{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the minutes\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# generates a dictionary of appropriate transcript paths\n",
    "# if you already have the text data, set path_to_local_txt to True. \n",
    "link_to_file_on_website = True\n",
    "\n",
    "# We are only interested in minutes in this kernel\n",
    "l_min = len(\"fomcminutes\")\n",
    "minute_links = {}\n",
    "\n",
    "# Before storing the links, we have some pitfalls to notice:\n",
    "# 1. Before 2007 (2006 to the past), minutes are written in HTML form.\n",
    "# 2. Before 2014 (2013 to the past), minutes and other disclosures are\n",
    "# ... located in a different URL to that of minutes from 2014 till now.\n",
    "\n",
    "# Accordingly, I split the scraper into 3 subparts.\n",
    "for year in range(1982, 2020): # from 1982 - 2013\n",
    "    if year < 1993:\n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/\"\n",
    "        path = \"fomchistorical\" + str(year) + \".htm\"\n",
    "        html_doc = requests.get(base_url + path)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = re.compile(r\"\\bMinutes\\b\"))\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        minute_links[str(year)] = [link_base_url + link[\"href\"] for link in links]\n",
    "        print(\"Year Complete: \", year)\n",
    "    elif year > 1992 and year < 2007:\n",
    "        # before 2007\n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/\"\n",
    "        path = \"fomchistorical\" + str(year) + \".htm\"\n",
    "        html_doc = requests.get(base_url + path)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = \"Minutes\")\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        final_link = []\n",
    "        for link in links:\n",
    "            if link[\"href\"][:4] == \"http\":\n",
    "                final_link.append(link[\"href\"])\n",
    "            else:\n",
    "                final_link.append(link_base_url + link[\"href\"])\n",
    "        minute_links[str(year)] = final_link\n",
    "        print(\"Year Complete: \", year)\n",
    "    elif year == 2007:\n",
    "        # For year 2007\n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/\"\n",
    "        path = \"fomchistorical\" + str(year) + \".htm\"\n",
    "        html_doc = requests.get(base_url + path)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = \"Minutes\")\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        final_link = []\n",
    "        for link in links:\n",
    "            if link[\"href\"][:4] == \"http\":\n",
    "                final_link.append(link[\"href\"])\n",
    "            else:\n",
    "                final_link.append(link_base_url + link[\"href\"])\n",
    "        minute_links[str(year)] = final_link\n",
    "        print(\"Year Complete: \", year)\n",
    "    elif year > 2007 and year < 2014:\n",
    "        # For year 2008 to 2013\n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/\"\n",
    "        path = \"fomchistorical\" + str(year) + \".htm\"\n",
    "        html_doc = requests.get(base_url + path)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = re.compile(\"PDF.*\"))\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        final_link = []\n",
    "        for link in links:\n",
    "            p = re.compile(\"[^/]*$\")\n",
    "            if p.search(link.get(\"href\")).group()[:(l_min+4)] == 'fomcminutes' + str(year):\n",
    "                if link[\"href\"][:4] == \"http\":\n",
    "                    final_link.append(link[\"href\"])\n",
    "                else:\n",
    "                    final_link.append(link_base_url + link[\"href\"])\n",
    "        minute_links[str(year)] = final_link\n",
    "        print(\"Year Complete: \", year)\n",
    "    else:\n",
    "        # After 2014, notice that \n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\"\n",
    "        html_doc = requests.get(base_url)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = re.compile(\"PDF.*\"))\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        final_link = []\n",
    "        for link in links:\n",
    "            p = re.compile(\"[^/]*$\")\n",
    "            if p.search(link.get(\"href\")).group()[:(l_min+4)] == 'fomcminutes' + str(year):\n",
    "                final_link.append(link_base_url + link[\"href\"])\n",
    "        minute_links[str(year)] = final_link\n",
    "        print(\"Year Complete: \", year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all paths and sort in increasing order\n",
    "sorted_transcripts = []\n",
    "for linkset in minute_links.values():\n",
    "    sorted_transcripts += linkset\n",
    "print(\"Number of Documents\", len(sorted_transcripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, scraping the minutes\n",
    "for year in minute_links.keys():\n",
    "    if not os.path.exists(\"./FOMCminutes/\" + year):\n",
    "        os.makedirs(\"./FOMCminutes/\" + year)\n",
    "    for link in minute_links[year]:\n",
    "        response = urllib.request.urlopen(str(link))\n",
    "        name = re.search(\"[^/]*$\", str(link))\n",
    "        print(link)\n",
    "        with open(\"./FOMCminutes/\" + year + \"/\" + name.group(), 'wb') as f:\n",
    "            f.write(response.read())\n",
    "        print(\"file downloaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
