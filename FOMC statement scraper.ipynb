{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the minutes\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Before 1993, the \"Record of Policy action\" is released ...\n",
    "# not immediately after each meeting. Therefore, we are not ...\n",
    "# interested in that period.\n",
    "\n",
    "# From 1994 until now, the statement after each meeting is published ...\n",
    "# immediately and they are our target in researching.\n",
    "l_state = len(\"monetary\")\n",
    "statement_links = {}\n",
    "\n",
    "# Again, we split our code into 3 subparts, before 2014 ...\n",
    "# 2014 and 2015, and from 2016 until now\n",
    "for year in range(1994, 2020): # from 1994 - 2019\n",
    "    if year < 2014:\n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/\"\n",
    "        path = \"fomchistorical\" + str(year) + \".htm\"\n",
    "        html_doc = requests.get(base_url + path)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = \"Statement\")\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        statement_links[str(year)] = [link_base_url + link[\"href\"] for link in links]\n",
    "        print(\"Year Completed: \", year)\n",
    "    elif year in [2014, 2015]:\n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\"\n",
    "        html_doc = requests.get(base_url)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = \"Statement\")\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        final_link = []\n",
    "        for link in links:\n",
    "            p = re.compile(\"[^/]*$\")\n",
    "            if p.search(link.get(\"href\")).group()[:(l_state+4)] == 'monetary' + str(year):\n",
    "                final_link.append(link_base_url + link[\"href\"])\n",
    "        statement_links[str(year)] = final_link\n",
    "        print(\"Year Completed: \", year)\n",
    "    else:\n",
    "        # After 2014, since all years are located in only one URL, we try to extract them out\n",
    "        base_url = \"https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\"\n",
    "        html_doc = requests.get(base_url)\n",
    "        soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
    "        links = soup.find_all(\"a\", string = re.compile(\"PDF.*\"))\n",
    "        link_base_url = \"https://www.federalreserve.gov\"\n",
    "        final_link = []\n",
    "        for link in links:\n",
    "            p = re.compile(\"[^/]*$\")\n",
    "            if p.search(link.get(\"href\")).group()[:(l_state+4)] == 'monetary' + str(year):\n",
    "                final_link.append(link_base_url + link[\"href\"])\n",
    "        statement_links[str(year)] = final_link\n",
    "        print(\"Year Completed: \", year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape them\n",
    "for year in statement_links.keys():\n",
    "    if not os.path.exists(\"./FOMCstatements/\" + year):\n",
    "        os.makedirs(\"./FOMCstatements/\" + year)\n",
    "    if int(year) < 2016:\n",
    "        for link in statement_links[year]:\n",
    "            p = re.compile(year + \"[0-9][0-9][0-9][0-9]\")\n",
    "            name = p.search(str(link))\n",
    "            response = urllib.request.urlretrieve(str(link), name.group() + \".txt\")\n",
    "            cwd = os.getcwd()\n",
    "            os.rename(cwd + \"/\" + name.group() + \".txt\", \"./FOMCstatements/\" + year + \"/\" + name.group() + \".txt\")\n",
    "        print(\"Download completed: \" + year)\n",
    "    else:\n",
    "        for link in statement_links[year]:\n",
    "            response = urllib.request.urlopen(str(link))\n",
    "            name = re.search(\"[^/]*$\", str(link))\n",
    "            with open(\"./FOMCstatements/\" + year + \"/\" + name.group(), 'wb') as f:\n",
    "                f.write(response.read())\n",
    "        print(\"Download completed\" + year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
